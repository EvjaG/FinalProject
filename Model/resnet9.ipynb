{"cells":[{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":22058,"status":"ok","timestamp":1646565328364,"user":{"displayName":"Evja","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"12685707936098631523"},"user_tz":-120},"id":"nMxeJ84HUqgk","outputId":"200cf9d7-4878-41a4-f481-ded8309fe2eb"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n","/content/drive/MyDrive/Final Project/model\n"]},{"output_type":"execute_result","data":{"text/plain":["['generator.py',\n"," '__pycache__',\n"," 'writer.py',\n"," 'datacounter.ipynb',\n"," 'data',\n"," 'resnet9.ipynb']"]},"metadata":{},"execution_count":2}],"source":["from google.colab import drive\n","drive.mount('/content/drive',force_remount=True)\n","# drive.mount('/content/drive')\n","import os\n","skipDataCreate=False\n","skipDataCreate=True\n","%cd /content/drive/MyDrive/Final Project/model\n","os.listdir()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Xnm3LxNz70eN","executionInfo":{"status":"aborted","timestamp":1646565303645,"user_tz":-120,"elapsed":17,"user":{"displayName":"Evja","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"12685707936098631523"}}},"outputs":[],"source":["!ls\n","# !rm -rf data\n","# !ls"]},{"cell_type":"code","execution_count":3,"metadata":{"executionInfo":{"elapsed":318,"status":"ok","timestamp":1646565337274,"user":{"displayName":"Evja","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"12685707936098631523"},"user_tz":-120},"id":"7_Tx0We6USkS"},"outputs":[],"source":["# for colab only\n","if not skipDataCreate:\n","  # if writer:\n","  #   del writer\n","# !rm data\n","  import writer\n","  writer.resizeFactor=22\n","  writer.how_many_orbits=600\n","  writer.mainFunc()\n","  del writer\n","  # writer.mainFunc()\n","\n","# print(os.getcwd())\n"]},{"cell_type":"code","execution_count":4,"metadata":{"executionInfo":{"elapsed":4,"status":"ok","timestamp":1646565337548,"user":{"displayName":"Evja","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"12685707936098631523"},"user_tz":-120},"id":"xUuxzL0O5eKs"},"outputs":[],"source":["# os.listdir()\n","# DIR = 'data'\n","# print (len([name for name in os.listdir(DIR) if os.path.isfile(os.path.join(DIR, name))]))"]},{"cell_type":"code","execution_count":5,"metadata":{"id":"2o-Tg9vJop9k","executionInfo":{"status":"ok","timestamp":1646565343096,"user_tz":-120,"elapsed":5551,"user":{"displayName":"Evja","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"12685707936098631523"}}},"outputs":[],"source":["import torch\n","import torchvision\n","import tarfile\n","import torch.nn as nn\n","import numpy as np\n","import torch.nn.functional as F\n","from torchvision.datasets.utils import download_url\n","from torchvision.datasets import ImageFolder\n","from torch.utils.data import DataLoader\n","import torchvision.transforms as tt\n","from torch.utils.data import random_split\n","from torchvision.utils import make_grid\n","import matplotlib\n","import matplotlib.pyplot as plt\n","import pandas as pd\n","# import time\n","# from sympy.solvers import solve\n","# from sympy import Symbol\n","# from sympy import *\n","import numpy as np\n","import matplotlib.pyplot as plt"]},{"cell_type":"markdown","metadata":{"id":"kUmOJP2BAxdJ"},"source":["# **Inequality Finder**"]},{"cell_type":"code","execution_count":6,"metadata":{"id":"Dl6I2LTFAxJX","executionInfo":{"status":"ok","timestamp":1646565343097,"user_tz":-120,"elapsed":6,"user":{"displayName":"Evja","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"12685707936098631523"}}},"outputs":[],"source":["x_points=[]\n","y_points=[]\n","lambdas=[]\n","def drawLine(x0,x1,y0,y1):\n","  x=[x0,x1]\n","  y=[y0,y1]\n","  plt.plot(x0, y0, marker=\"o\", markersize=5, markeredgecolor=\"red\", markerfacecolor=\"green\")#show line bettwen 2 ponits\n","  plt.plot(x,y)\n","  m=(y1-y0)/(x1-x0)\n","  return lambda x:y0+m*(x-x0)# return the line functionbettwen the 2 points\n","\n","\n","\n","\n","def cut(func1,func2,current):\n","  arr1=np.array([func1(x) for x in np.arange(0,max_distance,0.001)])\n","  plt.plot(np.linspace(0,max_distance,len(arr1)),arr1)#plot the paralel line\n","\n","  x = Symbol('x', real=True)\n","  x_l=solve(func1(x)-func2(x),x)# find cut\n","  min=max_distance\n","  for i in range(len(x_l)):\n","    if x_l[i]<min and x_l[i]>current:# look for the closet cut to the right of the graph\n","      min=x_l[i]\n","  y_current=func1(min)# get y of the cut    \n","  if min<max_distance:# we will ad the point if the cut doesnt pass the barier \n","    plt.plot(min, y_current, marker=\"o\", markersize=5, markeredgecolor=\"red\", markerfacecolor=\"green\")\n","    x_points.append(min)\n","    y_points.append(y_current)\n","  return min\n","\n","\n","def findInequality(L,P,Q,I,Z):\n","  global  x_points\n","  global  y_points\n","  x_points=[]\n","  y_points=[]\n","\n","  derivative=lambda x:-(L*P*Q*(x+I)**(P-1))/(Q*(x+I)**P+Z)**2+(L*P*Q*(x-I)**(P-1))/(Q*(x-I)**P+Z)**2+1\n","  funcatin=lambda x:x + (L / (Q * (x + I) ** P + Z)) - (L / (Q * (x - I) ** P + Z))\n","  x0=start\n","  arr2=np.array([funcatin(x) for x in np.arange(0,max_distance,0.001)])#dynamic function\n","\n","\n","  while x0<max_distance:# if the new point is bigger then max, just return \n","    plt.plot(np.linspace(0,max_distance,len(arr2)),arr2)\n","\n","    y0=funcatin(x0)\n","    m=derivative(x0)\n","\n","    lineA=lambda x:y0+m*(x-x0)+k\n","    lineB=lambda x:y0+m*(x-x0)-k\n","    #the 2 paralel lines \n","\n","    plt.plot(x0, y0, marker=\"o\", markersize=5, markeredgecolor=\"blue\", markerfacecolor=\"blue\")\n","    A_X_cut=cut(lineA,funcatin,x0)\n","    B_X_cut=cut(lineB,funcatin,x0)\n","\n","\n","    plt.show()\n","    if A_X_cut<0:# avoid negative\n","      A_X_cut=max_distance\n","    if B_X_cut<0:\n","      A_X_cut=max_distance   \n","\n","    x0=min(A_X_cut,B_X_cut)#minimum distance cut\n","\n","\n","  x = np.linspace(0,max_distance,500)\n","  plt.plot(x,x + (L / (Q * (x + I) ** P + Z)) - (L / (Q * (x - I) ** P + Z)))#show main dynamic\n","\n","\n","  for i in range(len(x_points)):\n","    plt.plot(x_points[i], y_points[i], marker=\"o\", markersize=5, markeredgecolor=\"red\", markerfacecolor=\"green\")#plot cut's on graph\n","  plt.show()\n","\n","\n","  lambdas=[]\n","  lambdas.append(drawLine(0,x_points[0],0,y_points[0]))\n","\n","\n","  for i in range(len(x_points)-1):\n","    lambdas.append(drawLine(x_points[i],x_points[i+1],y_points[i],y_points[i+1]))\n","\n","  lambdas.append(drawLine(x_points[len(x_points)-1],3,y_points[len(x_points)-1],3))\n","  plt.show()\n","  return lambdas,x_points,y_points"]},{"cell_type":"markdown","metadata":{"id":"e-Iig-FdXZ8s"},"source":["#Main"]},{"cell_type":"code","execution_count":7,"metadata":{"id":"6lt8Ux3pdY0b","executionInfo":{"status":"ok","timestamp":1646565343735,"user_tz":-120,"elapsed":12,"user":{"displayName":"Evja","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"12685707936098631523"}}},"outputs":[],"source":["\"\"\"\n","Original file is located at\n","    https://colab.research.google.com/drive/13R8T8i5OYbyyvjesEFC0cIwXebdGO4bp\n","\"\"\"\n","\n","\"\"\"We'll download the images in PNG format from [this page](https://course.fast.ai/datasets), using some helper functions from the `torchvision` and `tarfile` packages.\"\"\"\n","\n","#function  :  x + (L / (Q * (x + I) ** P + Z)) - (L / (Q * (x - I) ** P + Z)):https://www.desmos.com/calculator/0hiyjyun2f (move points to play with the parameters)\n","\n","\n","\n","\n","\n","setAll=False# will train and predict useing all the data ignoring the 2 above\n","#if false set the data manulaiy \n","#-----------------------------------------#\n","val_percent=0.5#x*5000 = dataset\n","train_percent=0.1#x*50000 = dataset\n","#old method:\n","# train_running_size=1000#train size of data {max is 50000}\n","# val_running_Size=1000#val size of data {max is 5000}\n","#-----------------------------------------#\n","\n","\n","\n","\n","#Relu parameters to compare\n","#-----------------------------------------#\n","addMaxRelu=False\n","addMean=False\n","HowManyTimesReRunRelu=1\n","#-----------------------------------------#\n","\n","\n","\n","\n","\n","checkCertainParams=True##if the one above is true set the parameters u want to check else it will igonre the value:\n","#-----------------------------------------------------------------------------------------#\n","L=55.9344471040698#0.1->2\n","Q=12 #0.01->0.2\n","P=2 #NO CHANGE\n","Z=10# NO CHANGE\n","I=0.0292401773821286 #1->3\n","howManyTimeToCheckTheCertainParams=1# how many times to run the cetrtain params \n","addMaxToCertain=False#will return the max score of the certain params\n","addMinToCertain=False#will return the min score of the certain params\n","addMeanToCertain=False#will return the mean of all the score's of the certain params\n","#-----------------------------------------------------------------------------------------#\n","\n","\n","\n","\n","#if checkCertainParams is false :config the range:\n","#-----------------------------------------------------------------------------------------#\n","LogarithmINC=True#insted of incresing when checking parameters with a constant , will will get to the to value useing geometric progression\n","\n","SIZEI=4#how many i to check\n","SIZEL=6#how many l to check\n","SIZEQ=7#how many q to check\n","#what number the paramter start and end\n","fromI=1\n","toI=10\n","\n","fromL=1\n","toL=50\n","\n","fromQ=0.01\n","toQ=10\n","#size of splits will, example fromI=1 toI=3,SIZEI=3 then i will check 1,2,3\n","#-----------------------------------------------------------------------------------------#\n","\n","\n","\n","#inequality parameters \n","#------------------------------------------------#\n","k=0.1#distance paralel\n","max_distance=3# maximum distance to find cut's,will return what found when pass the line \n","start=0#first paralel line will start from \n","runInequality=False# will run Inequality finder\n","setInequality=False# will set insted of dynamic Inequality function's ,above must be True\n","#------------------------------------------------#\n","\n","\n","#------------------nn parameters----------------#\n","batch_size = 128 #hyper parameter\n","epochs = 128\n","random_seed = 1\n","opt_func = torch.optim.Adam\n","\n","lr = 0.001#start learning rate\n","max_lr = 0.01# maximun learning rate\n","grad_clip = 0.1\n","weight_decay = 1e-4\n","opt_func = torch.optim.Adam#optimizer\n","#----------------------------------------------#\n","\n"]},{"cell_type":"code","execution_count":8,"metadata":{"id":"g3OlcxQVK605","executionInfo":{"status":"ok","timestamp":1646565343736,"user_tz":-120,"elapsed":12,"user":{"displayName":"Evja","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"12685707936098631523"}}},"outputs":[],"source":["#to not change:\n","#-------------#\n","\n","# setting the information needed for the nn for Inequality activation\n","# if runInequality:\n","\n","#   lambdas,x_points,y_points=findInequality(L,P,Q,I,Z)\n","\n","#   m=np.array([0.0]*len(lambdas))\n","  \n","#   x0=0.0\n","#   y0=0.0\n","#   b=[]\n","#   for i in range(len(x_points)):\n","#     m[i]=(y_points[i]-y0)/(x_points[i]-x0)\n","#     b.append(-m[i]*x0+y0)\n","#     x0=x_points[i]\n","#     y0=y_points[i]\n","\n","#   y1=10.0\n","#   x1=10.0\n","#   m[len(lambdas)-1]=(y1-y0)/(x1-x0)\n","#   b.append(-m[len(lambdas)-1]*x0+y0)\n","\n","#   \"\"\"Pick GPU if available, else CPU\"\"\"\n","#   if torch.cuda.is_available():\n","#       processor = torch.device('cuda') \n","#   else:\n","#       processor = torch.device('cpu') \n","\n","#   x_points=np.float32(np.array(x_points))\n","#   x_points=torch.tensor(x_points).to(device=processor)\n","\n","#   m=np.float32(m)\n","#   m=torch.tensor(m).to(device=processor)\n","\n","#   b=np.float32(np.array(b))\n","#   b=torch.tensor(b).to(device=processor)\n","\n","#   y_points=np.float32(np.array(y_points))\n","#   y_points=torch.tensor(y_points).to(device=processor)\n","\n","# val_size = 5000\n","\n","# #-------------#\n"]},{"cell_type":"markdown","metadata":{"id":"xvdg3F9aCIo5"},"source":["#Activation Function"]},{"cell_type":"code","execution_count":9,"metadata":{"id":"RzaA6sAZdgxB","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1646565343736,"user_tz":-120,"elapsed":11,"user":{"displayName":"Evja","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"12685707936098631523"}},"outputId":"8035fa21-d0eb-4717-a1c3-2006e3c9084c"},"outputs":[{"output_type":"stream","name":"stdout","text":["activation_function set\n"]}],"source":["if(checkCertainParams):\n","    L0=L\n","    Q0=Q\n","    I0=I\n","    Z0=Z\n","    P0=P\n","\n","def inequality_function(input):\n","    x=input\n","    x[x<0]=0\n","    c=x.clone()\n","    x[(0<c            )&  (c<=x_points[0])]=x[(0<c            )&(c<=x_points[0  ])]*m[0  ]+b[0  ]\n","    for i in range(len(x_points)-1):\n","      x[(x_points[i]<c)&(c<=x_points[i+1])]=x[(x_points[i]<c  )&(c<=x_points[i+1])]*m[i+1]+b[i+1]\n","    x[(x_points[len(x_points)-1]<c)       ]=x[(x_points[len(x_points)-1]<c)       ]*m[len(x_points)]+b[len(x_points)]\n","    return x\n","\n","class Inequality_function(nn.Module):\n","    def __init__(self):\n","        super().__init__() # init the base class\n","    def forward(self, input):\n","        return inequality_function(input) \n","\n","def dynamic(input):\n","    x=input\n","    x[x<0]=0\n","    if (checkCertainParams):\n","        x = x + (L0 / (Q0 * (x + I0) ** P0 + Z0)) - (L0 / (Q0 * (x - I0) ** P0 + Z0))\n","    else:\n","        x = x + (L / (Q * (x + I) ** P + Z)) - (L / (Q * (x - I) ** P + Z))\n","    return x\n","\n","class Dynamic(nn.Module):\n","    def __init__(self):\n","        super().__init__() # init the base class\n","    def forward(self, input):\n","        return dynamic(input) \n","\n","def relu(input):\n","    x=input\n","    x[x<0]=0\n","    return x\n","\n","class RELU(nn.Module):\n","    def __init__(self):\n","        super().__init__() # init the base class\n","    def forward(self, input):\n","        return relu(input) # simply apply already implemented SiLU\n","\n","def setParams(L_,Q_,P_,Z_,I_):\n","    global L\n","    global Q\n","    global P\n","    global Z\n","    global I\n","    L = L_\n","    Q = Q_\n","    P = P_\n","    Z = Z_\n","    I = I_\n","\n","    pass\n","\n","activation_function = RELU()\n","print(\"activation_function set\")\n","\n"]},{"cell_type":"markdown","metadata":{"id":"umKX-1TSiOqj"},"source":["# Load Data"]},{"cell_type":"code","execution_count":10,"metadata":{"id":"e7-Xj6KudwpQ","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1646565348784,"user_tz":-120,"elapsed":5058,"user":{"displayName":"Evja","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"12685707936098631523"}},"outputId":"5daf9292-e9c8-40b6-c38e-312e27b57a78"},"outputs":[{"output_type":"stream","name":"stdout","text":["['generator.py', '__pycache__', 'writer.py', 'datacounter.ipynb', 'data', 'resnet9.ipynb']\n"]}],"source":["\"\"\"### Loading and Processing Dataset\"\"\"\n","\n","\n","# Download the dataset\n","# dataset_url = 'https://s3.amazonaws.com/fast-ai-imageclas/cifar100.tgz'\n","# download_url(dataset_url, '.')\n","\n","# #Extract from archive\n","# with tarfile.open('./cifar100.tgz', 'r:gz') as tar:\n","#   tar.extractall(path='./data')\n","\n","# Look into the data directory\n","data_dir = './data/'\n","print(os.listdir())\n","folders = os.listdir(data_dir + \"/train\")\n","classes=[]\n","# for folder in folders:\n","#   classes+=os.listdir(data_dir + \"/train/\"+folder)\n","classes=os.listdir(data_dir + \"/train\")\n","\n","\n","\n","#Data transforms (normalization and data augmentation)\n","\n","stats = ((0.4914, 0.4822, 0.4465),\n","         (0.2023, 0.1994, 0.2010))\n","\n","train_tfms = tt.Compose([tt.RandomCrop(32, padding=4, padding_mode='reflect'),\n","                         tt.RandomHorizontalFlip(),\n","                         tt.ToTensor(),\n","                         tt.Normalize(*stats, inplace=True)])\n","\n","valid_tfms = tt.Compose([tt.ToTensor(), tt.Normalize(*stats)])\n","\n","# PyTorch datasets\n","train_ds=[]\n","valid_ds=[]\n","# for folder in folders:\n","#   train_ds+=ImageFolder(data_dir+'/train/'+folder, train_tfms)\n","#   valid_ds+=ImageFolder(data_dir+'/test/'+folder, valid_tfms)\n","train_ds = ImageFolder(data_dir+'/train', train_tfms)\n","valid_ds = ImageFolder(data_dir+'/test', valid_tfms)\n","\n","# if not setAll :\n","#     data_S = list(range(0, len(train_ds),int(1/train_percent)))\n","#     test_S = list(range(0, len(valid_ds), int(1/val_percent)))\n","\n","#     train_ds = torch.utils.data.Subset(train_ds, data_S)\n","#     valid_ds = torch.utils.data.Subset(valid_ds, test_S)\n","    \n","\n","# Pytorch Data Loaders\n","train_dl = DataLoader(train_ds, batch_size, shuffle=True, num_workers=2, pin_memory=True)\n","valid_dl = DataLoader(valid_ds, batch_size*2, num_workers=2, pin_memory=True)\n","\n","\"\"\"### Uploading on GPU\"\"\"\n","\n","### Using a GPU\n","def get_default_device():\n","    \"\"\"Pick GPU if available, else CPU\"\"\"\n","    if torch.cuda.is_available():\n","        return torch.device('cuda')\n","        print(\"set on gpu\")\n","    else:\n","        return torch.device('cpu')\n","        print(\"set on cpu\")\n","\n","def to_device(data, device):\n","    \"\"\"Move tensor(s) to chosen device\"\"\"\n","    if isinstance(data, (list,tuple)):\n","        return [to_device(x, device) for x in data]\n","    return data.to(device, non_blocking=True)\n","\n","class DeviceDataLoader():\n","    \"\"\"Wrap a dataloader to move data to a device\"\"\"\n","    def __init__(self, dl, device):\n","        self.dl = dl\n","        self.device = device\n","\n","    def __iter__(self):\n","        \"\"\"Yield a batch of data after moving it to device\"\"\"\n","        for b in self.dl:\n","            yield to_device(b, self.device)\n","\n","    def __len__(self):\n","        \"\"\"Number of batches\"\"\"\n","        return len(self.dl)\n","\n","device = get_default_device()\n","device\n","\n","train_dl = DeviceDataLoader(train_dl, device)\n","valid_dl = DeviceDataLoader(valid_dl, device)"]},{"cell_type":"markdown","metadata":{"id":"v2DhICEXqo2-"},"source":["# RESNET 9"]},{"cell_type":"code","execution_count":11,"metadata":{"id":"l2imA4jcez78","executionInfo":{"status":"ok","timestamp":1646565349133,"user_tz":-120,"elapsed":352,"user":{"displayName":"Evja","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"12685707936098631523"}}},"outputs":[],"source":["\n","def accuracy(outputs, labels):\n","    _, preds = torch.max(outputs, dim=1)\n","    return torch.tensor(torch.sum(preds == labels).item() / len(preds))\n","\n","class ImageClassificationBase(nn.Module):\n","    def training_step(self, batch):\n","        images, labels = batch\n","        out = self(images)                  # Generate predictions\n","        loss = F.cross_entropy(out, labels) # Calculate loss\n","        return loss\n","\n","    def validation_step(self, batch):\n","        images, labels = batch\n","        out = self(images)                    # Generate predictions\n","        loss = F.cross_entropy(out, labels)   # Calculate loss\n","        acc = accuracy(out, labels)           # Calculate accuracy\n","        return {'val_loss': loss.detach(), 'val_acc': acc}\n","\n","    def validation_epoch_end(self, outputs):\n","        batch_losses = [x['val_loss'] for x in outputs]\n","        epoch_loss = torch.stack(batch_losses).mean()   # Combine losses\n","        batch_accs = [x['val_acc'] for x in outputs]\n","        epoch_acc = torch.stack(batch_accs).mean()      # Combine accuracies\n","        return {'val_loss': epoch_loss.item(), 'val_acc': epoch_acc.item()}\n","\n","    def epoch_end(self, epoch, result):\n","        print(\"Epoch [{}], last_lr: {:.5f}, train_loss: {:.4f}, val_loss: {:.4f}, val_acc: {:.4f}\".format(\n","            epoch, result['lrs'][-1], result['train_loss'], result['val_loss'], result['val_acc']))\n","\n","\"\"\"Building our architecture:\"\"\"\n","# activation_function=nn.ReLU()\n","def conv_block(in_channels, out_channels, pool=False):\n","    layers = [nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1),\n","              nn.BatchNorm2d(out_channels),\n","            #   activation_function]\n","              nn.ReLU()]\n","    if pool: layers.append(nn.MaxPool2d(2))\n","    return nn.Sequential(*layers)\n","\n","class ResNet9(ImageClassificationBase):\n","    def __init__(self, in_channels, num_classes):\n","        super().__init__()\n","\n","        self.conv1 = conv_block(in_channels,9)\n","        self.conv2 = conv_block(9, 81, pool=True)\n","        self.res1 = nn.Sequential(conv_block(81, 81), conv_block(81, 81))\n","\n","        self.conv3 = conv_block(81, 162, pool=True)\n","        self.conv4 = conv_block(162, 324, pool=True)\n","        self.res2 = nn.Sequential(conv_block(324, 324), conv_block(324, 324))\n","\n","        \n","        self.conv5 = conv_block(324, 648, pool=True)\n","        self.conv6 = conv_block(648, 1296, pool=True)\n","        self.res3 = nn.Sequential(conv_block(1296, 1296), conv_block(1296, 1296))\n","\n","        \n","        self.conv7 = conv_block(1296, 2592, pool=True)\n","        self.conv8 = conv_block(2592, 5184, pool=True)\n","        self.res4 = nn.Sequential(conv_block(5184, 5184), conv_block(5184, 5184))\n","\n","        self.classifier = nn.Sequential(nn.MaxPool2d(2),\n","                                        nn.Flatten(),\n","                                        nn.Dropout(0.5),\n","                                        nn.Linear(44064, num_classes))\n","                                        # nn.Linear(324, num_classes))\n","\n","    def forward(self, xb):\n","        out = self.conv1(xb)\n","        out = self.conv2(out)\n","        out = self.res1(out) + out\n","        out = self.conv3(out)\n","        out = self.conv4(out)\n","        out = self.res2(out) + out\n","        out = self.conv5(out)\n","        out = self.conv6(out)\n","        # out = self.res3(out) + out\n","        out = self.classifier(out)\n","\n","        \n","        return out\n","\n","\n","\n","\"\"\"### Training the Model\n","The improvements in fit functions are:\n","1. Learning rate scheduling: Instead of using a fixed learning rate, we will use a learning rate scheduler, which will change the learning rate after every batch of training. We will use one cycle policy [1cycle policy](https://sgugger.github.io/the-1cycle-policy.html).\n","2. Weight Decay: A regularization technique which prevents the weights from becoming too large by adding an additional term to the loss function.\n","3. Gradient clipping: Apart from the layer weights and outputs, it also helpful to limit the values of gradients to a small range to prevent undesirable changes in parameters due to large gradient values\n","\n","\"\"\"\n","\n","@torch.no_grad()\n","def evaluate(model, val_loader):\n","    model.eval()\n","    outputs = [model.validation_step(batch) for batch in val_loader]\n","    return model.validation_epoch_end(outputs)\n","\n","def get_lr(optimizer):\n","    for param_group in optimizer.param_groups:\n","        return param_group['lr']\n","\n","def fit_one_cycle(epochs, max_lr, model, train_loader, val_loader,\n","                  weight_decay=0, grad_clip=None, opt_func=torch.optim.SGD):\n","    torch.cuda.empty_cache()\n","    history = []\n","\n","    # Set up cutom optimizer with weight decay\n","    optimizer = opt_func(model.parameters(), max_lr, weight_decay=weight_decay)\n","    # Set up one-cycle learning rate scheduler\n","    sched = torch.optim.lr_scheduler.OneCycleLR(optimizer, max_lr, epochs=epochs,\n","                                                steps_per_epoch=len(train_loader))\n","\n","    for epoch in range(epochs):\n","        # Training Phase\n","        model.train()\n","        train_losses = []\n","        lrs = []\n","        for batch in train_loader:\n","            loss = model.training_step(batch)\n","            train_losses.append(loss)\n","            loss.backward()\n","\n","            # Gradient clipping\n","            if grad_clip:\n","                nn.utils.clip_grad_value_(model.parameters(), grad_clip)\n","\n","            optimizer.step()\n","            optimizer.zero_grad()\n","\n","            # Record & update learning rate\n","            lrs.append(get_lr(optimizer))\n","            sched.step()\n","\n","        # Validation phase\n","        result = evaluate(model, val_loader)\n","        result['train_loss'] = torch.stack(train_losses).mean().item()\n","        result['lrs'] = lrs\n","        model.epoch_end(epoch, result)\n","        history.append(result)\n","    return history"]},{"cell_type":"markdown","metadata":{"id":"V3wPaDxFqsrf"},"source":["TRAIN"]},{"cell_type":"code","execution_count":12,"metadata":{"id":"8Ebj2fqiCmpC","executionInfo":{"status":"ok","timestamp":1646565349133,"user_tz":-120,"elapsed":5,"user":{"displayName":"Evja","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"12685707936098631523"}}},"outputs":[],"source":["def setFunc():# set dynamic or Inequality\n","  if setInequality:\n","    print(\"Inequality_function set\")\n","    return Inequality_function()\n","   \n","  else:\n","    print(\"Dynamic set\")\n","    return Dynamic()\n"]},{"cell_type":"code","source":["max=0"],"metadata":{"id":"GdetGSoewyE8","executionInfo":{"status":"ok","timestamp":1646565349134,"user_tz":-120,"elapsed":5,"user":{"displayName":"Evja","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"12685707936098631523"}}},"execution_count":13,"outputs":[]},{"cell_type":"code","execution_count":14,"metadata":{"id":"4SQcsxI4UGnB","colab":{"base_uri":"https://localhost:8080/","height":397},"executionInfo":{"status":"error","timestamp":1646565414420,"user_tz":-120,"elapsed":65291,"user":{"displayName":"Evja","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"12685707936098631523"}},"outputId":"78f9d37f-f926-4293-f1f6-8bc2689957bc"},"outputs":[{"output_type":"error","ename":"RuntimeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","\u001b[0;32m<ipython-input-14-1526304921fa>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m   \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_device\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mResNet9\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m   \u001b[0;31m# model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m   \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_dl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m   \u001b[0mmax\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'val_acc'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'val_acc'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0;36m0.6\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/autograd/grad_mode.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-11-07851ea4e9e5>\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(model, val_loader)\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 97\u001b[0;31m     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalidation_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mval_loader\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     98\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalidation_epoch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-11-07851ea4e9e5>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 97\u001b[0;31m     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalidation_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mval_loader\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     98\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalidation_epoch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-11-07851ea4e9e5>\u001b[0m in \u001b[0;36mvalidation_step\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mvalidation_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m)\u001b[0m                    \u001b[0;31m# Generate predictions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcross_entropy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m   \u001b[0;31m# Calculate loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0macc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maccuracy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m           \u001b[0;31m# Calculate accuracy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-11-07851ea4e9e5>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, xb)\u001b[0m\n\u001b[1;32m     69\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 71\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     72\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mres1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    139\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 141\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    142\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/batchnorm.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    177\u001b[0m             \u001b[0mbn_training\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    178\u001b[0m             \u001b[0mexponential_average_factor\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 179\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    180\u001b[0m         )\n\u001b[1;32m    181\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mbatch_norm\u001b[0;34m(input, running_mean, running_var, weight, bias, training, momentum, eps)\u001b[0m\n\u001b[1;32m   2281\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2282\u001b[0m     return torch.batch_norm(\n\u001b[0;32m-> 2283\u001b[0;31m         \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrunning_mean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrunning_var\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmomentum\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackends\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcudnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menabled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2284\u001b[0m     )\n\u001b[1;32m   2285\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 5.26 GiB (GPU 0; 15.90 GiB total capacity; 8.56 GiB already allocated; 649.75 MiB free; 14.27 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"]}],"source":["while True:\n","  model = to_device(ResNet9(3,10), device)\n","  # model\n","  history = [evaluate(model, valid_dl)]\n","  max = np.max((max,history[0]['val_acc']))\n","  if history[0]['val_acc'] >= 0.6:\n","    break\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_18v-RZnUGnC","executionInfo":{"status":"aborted","timestamp":1646565414419,"user_tz":-120,"elapsed":5,"user":{"displayName":"Evja","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"12685707936098631523"}}},"outputs":[],"source":["# history = [evaluate(model, valid_dl)]\n","print(history[0]['val_acc'])\n","max"]}],"metadata":{"accelerator":"GPU","colab":{"background_execution":"on","collapsed_sections":["kUmOJP2BAxdJ"],"machine_shape":"hm","name":"resnet9.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.7"}},"nbformat":4,"nbformat_minor":0}