{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":12309,"status":"ok","timestamp":1652158566203,"user":{"displayName":"Evja","userId":"12685707936098631523"},"user_tz":-180},"id":"lkwALRFTa2uF","outputId":"b833bdcf-a197-42ae-b59b-f6610a600831"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n","/content/drive/MyDrive/Final Project/model\n"]},{"output_type":"execute_result","data":{"text/plain":["['generator.py',\n"," '__pycache__',\n"," 'datacounter.ipynb',\n"," 'resnet9.ipynb',\n"," 'writer.py',\n"," 'data',\n"," 'data.csv',\n"," 'data 1.csv',\n"," 'data 2.csv',\n"," 'data 3.csv',\n"," 'bestParams_old',\n"," 'bestParams.txt',\n"," 'rnn.ipynb']"]},"metadata":{},"execution_count":1}],"source":["from google.colab import drive\n","drive.mount('/content/drive',force_remount=True)\n","# drive.mount('/content/drive')\n","import os\n","skipDataCreate=False\n","skipDataCreate=True\n","%cd /content/drive/MyDrive/Final Project/model\n","os.listdir()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":8,"status":"ok","timestamp":1652158566203,"user":{"displayName":"Evja","userId":"12685707936098631523"},"user_tz":-180},"id":"x3xpX90RbXjp","outputId":"3c67aaec-99c4-4181-c8b6-ae0f9f26f063"},"outputs":[{"output_type":"stream","name":"stdout","text":["Skipped\n"]}],"source":["# # for colab only\n","if not skipDataCreate:\n","  # if writer:\n","  #   del writer\n","# !rm data\n","  import writer\n","  writer.resizeFactor=1\n","  writer.how_many_orbits=20\n","  writer.generator.num_of_points=1000\n","  writer.csvWrite=True\n","  writer.mainFunc()\n","  del writer\n","  # writer.mainFunc()\n","else:\n","  print(\"Skipped\")\n","\n","# # print(os.getcwd())\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"yw-6BbBJ1Zlj"},"outputs":[],"source":["# LSTM for international airline passengers problem with memory\n","import numpy\n","import matplotlib.pyplot as plt\n","from pandas import read_csv\n","import math\n","from keras.models import Sequential\n","from keras.layers import Dense\n","from keras.layers import LSTM\n","from sklearn.preprocessing import MinMaxScaler\n","from sklearn.metrics import mean_squared_error\n","import pdb; \n","\n","# convert an array of values into a dataset matrix\n","def create_dataset(dataset, look_back=1):\n","\tdataX, dataY = [], []\n","\tfor i in range(len(dataset)-look_back-1):\n","\t\ta = dataset[i:(i+look_back), 0]\n","\t\tdataX.append(a)\n","\t\tdataY.append(dataset[i + look_back, 0])\n","\treturn numpy.array(dataX), numpy.array(dataY)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"VQzDxFia3YCP"},"outputs":[],"source":["def LSTM_Reg(dataset,train_size=0.67,batch_size=1,train_epochs=100,per_train_epochs=5,plot=False,look_back = 3,verbose=1):\n","  # pre-prep the data\n","  scaler = MinMaxScaler(feature_range=(0, 1))\n","  dataset = scaler.fit_transform(dataset) # normalize\n","  # split into train and test sets\n","  train_size = int(len(dataset) * train_size)\n","  test_size = len(dataset) - train_size\n","  train, test = dataset[0:train_size,:], dataset[train_size:len(dataset),:]\n","  # reshape into X=t and Y=t+1\n","  trainX, trainY = create_dataset(train, look_back)\n","  testX, testY = create_dataset(test, look_back)\n","  # reshape input to be [samples, time steps, features]\n","  trainX = numpy.reshape(trainX, (trainX.shape[0], trainX.shape[1], 1))\n","  testX = numpy.reshape(testX, (testX.shape[0], testX.shape[1], 1))\n","    \n","  model = Sequential()\n","  model.add(LSTM(40, batch_input_shape=(batch_size, look_back, 1), stateful=True))\n","  model.add(Dense(10))\n","  model.add(Dense(1))\n","  model.compile(loss='mean_squared_error', optimizer='adam')\n","  for i in range(train_epochs):\n","    if verbose:\n","      print(\"Superepoch %d of %d\" % (i,train_epochs))\n","    model.fit(trainX, trainY, epochs=per_train_epochs, batch_size=batch_size, verbose=verbose, shuffle=False)\n","    model.reset_states()\n","  # make predictions\n","  trainPredict = model.predict(trainX, batch_size=batch_size)\n","  model.reset_states()\n","  testPredict = model.predict(testX, batch_size=batch_size)\n","  # invert predictions\n","  trainPredict = scaler.inverse_transform(trainPredict)\n","  trainY = scaler.inverse_transform([trainY])\n","  testPredict = scaler.inverse_transform(testPredict)\n","  testY = scaler.inverse_transform([testY])\n","  # calculate root mean squared error\n","  trainScore = math.sqrt(mean_squared_error(trainY[0], trainPredict[:,0]))\n","  testScore = math.sqrt(mean_squared_error(testY[0], testPredict[:,0]))\n","  if verbose:\n","    print('Train Score: %.2f RMSE' % (trainScore))\n","    print('Test Score: %.2f RMSE' % (testScore))\n","  \n","  \n","  # shift train predictions for plotting\n","\n","  if plot:\n","    # PLT\n","    trainPredictPlot = numpy.empty_like(dataset)\n","    trainPredictPlot[:, :] = numpy.nan\n","    trainPredictPlot[look_back:len(trainPredict)+look_back, :] = trainPredict\n","    # shift test predictions for plotting\n","    testPredictPlot = numpy.empty_like(dataset)\n","    testPredictPlot[:, :] = numpy.nan\n","    testPredictPlot[len(trainPredict)+(look_back*2)+1:len(dataset)-1, :] = testPredict\n","    # plot baseline and predictions\n","    plt.plot(scaler.inverse_transform(dataset))\n","    plt.plot(trainPredictPlot)\n","    plt.plot(testPredictPlot)\n","    plt.show()\n","  return testScore"]},{"cell_type":"code","source":["# fix random seed for reproducibility\n","numpy.random.seed(7)\n","xyz=[\"y\",\"x\",\"z\"]\n","\n","bestParams=()\n","maxScore=0\n","verbose=0\n","try:\n","  with open(\"bestParams.txt\") as BC:\n","    BC=BC.readlines()\n","    maxScore=float(BC[1])\n","    BC=BC[0][1:-2].split(', ')\n","    bestParams=tuple(map(float,BC))\n","    print(\"Score file loaded, score is:\")\n","    print(maxScore)\n","    print(\"Best parameters found for now are the following:\")\n","    print(BC)\n","except IOError:\n","  print(\"Score file not found, starting from 0\")\n","\n","from datetime import datetime\n","today = datetime.now()\n","d4 = today.strftime(\"%b-%d-%Y_%H-%M-%S\")\n","logfile = open(f\"log_{d4}.txt\",\"a+\")\n","\n","# iterate through various parameters to find the best ones\n","for per_train_epochs in range(1,9,2):\n","  for look_back in range(2,8):\n","    for train_epochs in range(1,10,1):\n","      for train_size in numpy.arange(0.65,0.95,0.05):        \n","        outerScore=0\n","        for j in range(1,4):\n","          curScore=0\n","          for i in range(1,4):\n","            # load the dataset with given column\n","            dataframe = read_csv(f'data {j}.csv', usecols=[i], engine='python')\n","            dataset = dataframe.values\n","            dataset = dataset.astype('float32')\n","            if verbose:\n","              print(f'{xyz[i-1]} score:')\n","            score = LSTM_Reg(dataset,per_train_epochs=per_train_epochs,look_back=look_back,train_epochs=train_epochs,train_size=float(train_size),verbose=verbose)\n","            if type(score)==type(None):\n","              score=0\n","            curScore += score          \n","          curScore/=3\n","          outerScore+=curScore\n","        outerScore/=3\n","        \n","        d4 = today.strftime(\"%b-%d-%Y_%H-%M-%S\")\n","        logfile.write(f\"{d4}\\t|\\t{outerScore}\\t|\\t{(per_train_epochs,look_back,train_epochs,train_size)}\\n\")\n","        if outerScore > maxScore:\n","          logfile.write(f\"***\\nCHANGE\\n***\")\n","          print(f'Old score ({maxScore}) => New Score ({outerScore})')\n","          maxScore=outerScore\n","          bestParams=(per_train_epochs,look_back,train_epochs,train_size)\n","          with open('bestParams.txt', 'w') as writefile:\n","            writefile.write(f\"{bestParams}\\n{maxScore}\")"],"metadata":{"id":"3LfeJYJ52_2I","colab":{"base_uri":"https://localhost:8080/"},"outputId":"546366a5-0c51-401b-8f94-dd15e1205342"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Score file loaded, score is:\n","0.1850603527152933\n","Best parameters found for now are the following:\n","['1', '2', '1', '0.65']\n","Old score (0.1850603527152933) => New Score (0.19842257428379828)\n"]}]},{"cell_type":"code","source":["# # print(f\"best Params:\\n{bestParams}\")\n","# # print(f\"best score:\\n{maxScore}\")\n","# with open('bestParams', 'w') as writefile:\n","#     writefile.write(f\"{bestParams}\\n{maxScore}\")"],"metadata":{"id":"OGV9gsajGe44"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!ls\n","# "],"metadata":{"id":"vJS_ycCziHnf","executionInfo":{"status":"ok","timestamp":1652159132629,"user_tz":-180,"elapsed":8,"user":{"displayName":"Evja","userId":"12685707936098631523"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"501e3aaf-8544-43c1-a12a-85c3c6ebc02d"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":[" bestParams_old  'data 2.csv'\t      generator.py\t\t     rnn.ipynb\n"," bestParams.txt  'data 3.csv'\t      log_May-10-2022_00-00-00.txt   writer.py\n"," data\t\t  datacounter.ipynb   __pycache__\n","'data 1.csv'\t  data.csv\t      resnet9.ipynb\n"]}]},{"cell_type":"markdown","source":["# New Section"],"metadata":{"id":"a1nXlAlWWSUG"}}],"metadata":{"colab":{"collapsed_sections":[],"name":"rnn.ipynb","provenance":[],"mount_file_id":"19zJgOdFoJdHrG7Dq_QVs7h2R8kpK8siO","authorship_tag":"ABX9TyPobmeunB12xhQXQSYBIv4s"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}