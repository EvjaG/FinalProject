{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nMxeJ84HUqgk","executionInfo":{"status":"ok","timestamp":1654722149946,"user_tz":-180,"elapsed":3528,"user":{"displayName":"Evja","userId":"12685707936098631523"}},"outputId":"bcb7f911-8eeb-485d-b27a-1b8be4221b04"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n","/content/drive/MyDrive/Final Project/model\n"]},{"output_type":"execute_result","data":{"text/plain":["['generator.py',\n"," '__pycache__',\n"," 'datacounter.ipynb',\n"," 'resnet9.ipynb',\n"," 'log_May-10-2022_20-03-02.txt',\n"," 'log_May-10-2022_23-28-13.txt',\n"," 'writer.py',\n"," 'log_May-10-2022_23-38-57.txt',\n"," 'log_May-10-2022_23-42-27.txt',\n"," 'log_May-10-2022_23-43-12.txt',\n"," 'log_May-10-2022_23-44-36.txt',\n"," 'log_May-18-2022_22-22-49.txt',\n"," 'bestParams.txt',\n"," 'rnn.ipynb',\n"," 'writer.ipynb',\n"," 'data']"]},"metadata":{},"execution_count":1}],"source":["from google.colab import drive\n","drive.mount('/content/drive',force_remount=True)\n","# drive.mount('/content/drive')\n","import os\n","skipDataCreate=False\n","skipDataCreate=True\n","%cd /content/drive/MyDrive/Final Project/model\n","os.listdir()"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Xnm3LxNz70eN","executionInfo":{"status":"ok","timestamp":1654722150362,"user_tz":-180,"elapsed":427,"user":{"displayName":"Evja","userId":"12685707936098631523"}},"outputId":"7084b423-bdcf-48f9-ba64-02cf4b0967d7"},"outputs":[{"output_type":"stream","name":"stdout","text":["bestParams.txt\t\t      log_May-10-2022_23-38-57.txt  resnet9.ipynb\n","data\t\t\t      log_May-10-2022_23-42-27.txt  rnn.ipynb\n","datacounter.ipynb\t      log_May-10-2022_23-43-12.txt  writer.ipynb\n","generator.py\t\t      log_May-10-2022_23-44-36.txt  writer.py\n","log_May-10-2022_20-03-02.txt  log_May-18-2022_22-22-49.txt\n","log_May-10-2022_23-28-13.txt  __pycache__\n","bestParams.txt\t\t      log_May-10-2022_23-38-57.txt  resnet9.ipynb\n","data\t\t\t      log_May-10-2022_23-42-27.txt  rnn.ipynb\n","datacounter.ipynb\t      log_May-10-2022_23-43-12.txt  writer.ipynb\n","generator.py\t\t      log_May-10-2022_23-44-36.txt  writer.py\n","log_May-10-2022_20-03-02.txt  log_May-18-2022_22-22-49.txt\n","log_May-10-2022_23-28-13.txt  __pycache__\n"]}],"source":["!ls\n","# !rm -rf data\n","!ls"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7_Tx0We6USkS","executionInfo":{"status":"ok","timestamp":1654722150362,"user_tz":-180,"elapsed":8,"user":{"displayName":"Evja","userId":"12685707936098631523"}},"outputId":"d792a640-429b-4155-926b-f11e10137843"},"outputs":[{"output_type":"stream","name":"stdout","text":["Skipped\n"]}],"source":["# for colab only\n","if not skipDataCreate:\n","  # if writer:\n","  #   del writer\n","# !rm data\n","  import writer\n","  writer.resizeFactor=1\n","  writer.csvWrite=True\n","  writer.how_many_orbits=340\n","  writer.mainFunc()\n","  del writer\n","  # writer.mainFunc()\n","else:\n","  print(\"Skipped\")\n","\n","# print(os.getcwd())\n"]},{"cell_type":"code","execution_count":4,"metadata":{"id":"xUuxzL0O5eKs","executionInfo":{"status":"ok","timestamp":1654722150363,"user_tz":-180,"elapsed":6,"user":{"displayName":"Evja","userId":"12685707936098631523"}}},"outputs":[],"source":["# os.listdir()\n","# DIR = 'data'\n","# print (len([name for name in os.listdir(DIR) if os.path.isfile(os.path.join(DIR, name))]))"]},{"cell_type":"code","execution_count":5,"metadata":{"id":"2o-Tg9vJop9k","executionInfo":{"status":"ok","timestamp":1654722151436,"user_tz":-180,"elapsed":1079,"user":{"displayName":"Evja","userId":"12685707936098631523"}}},"outputs":[],"source":["import torch\n","import torchvision\n","import tarfile\n","import torch.nn as nn\n","import numpy as np\n","import torch.nn.functional as F\n","from torchvision.datasets.utils import download_url\n","from torchvision.datasets import ImageFolder\n","from torch.utils.data import DataLoader\n","import torchvision.transforms as tt\n","from torch.utils.data import random_split\n","from torchvision.utils import make_grid\n","import matplotlib\n","import matplotlib.pyplot as plt\n","import pandas as pd\n","# import time\n","# from sympy.solvers import solve\n","# from sympy import Symbol\n","# from sympy import *\n","import numpy as np\n","import matplotlib.pyplot as plt"]},{"cell_type":"markdown","metadata":{"id":"kUmOJP2BAxdJ"},"source":["# **Inequality Finder**"]},{"cell_type":"code","execution_count":6,"metadata":{"id":"Dl6I2LTFAxJX","executionInfo":{"status":"ok","timestamp":1654722151437,"user_tz":-180,"elapsed":11,"user":{"displayName":"Evja","userId":"12685707936098631523"}}},"outputs":[],"source":["x_points=[]\n","y_points=[]\n","lambdas=[]\n","def drawLine(x0,x1,y0,y1):\n","  x=[x0,x1]\n","  y=[y0,y1]\n","  plt.plot(x0, y0, marker=\"o\", markersize=5, markeredgecolor=\"red\", markerfacecolor=\"green\")#show line bettwen 2 ponits\n","  plt.plot(x,y)\n","  m=(y1-y0)/(x1-x0)\n","  return lambda x:y0+m*(x-x0)# return the line functionbettwen the 2 points\n","\n","\n","\n","\n","def cut(func1,func2,current):\n","  arr1=np.array([func1(x) for x in np.arange(0,max_distance,0.001)])\n","  plt.plot(np.linspace(0,max_distance,len(arr1)),arr1)#plot the paralel line\n","\n","  x = Symbol('x', real=True)\n","  x_l=solve(func1(x)-func2(x),x)# find cut\n","  min=max_distance\n","  for i in range(len(x_l)):\n","    if x_l[i]<min and x_l[i]>current:# look for the closet cut to the right of the graph\n","      min=x_l[i]\n","  y_current=func1(min)# get y of the cut    \n","  if min<max_distance:# we will ad the point if the cut doesnt pass the barier \n","    plt.plot(min, y_current, marker=\"o\", markersize=5, markeredgecolor=\"red\", markerfacecolor=\"green\")\n","    x_points.append(min)\n","    y_points.append(y_current)\n","  return min\n","\n","\n","def findInequality(L,P,Q,I,Z):\n","  global  x_points\n","  global  y_points\n","  x_points=[]\n","  y_points=[]\n","\n","  derivative=lambda x:-(L*P*Q*(x+I)**(P-1))/(Q*(x+I)**P+Z)**2+(L*P*Q*(x-I)**(P-1))/(Q*(x-I)**P+Z)**2+1\n","  funcatin=lambda x:x + (L / (Q * (x + I) ** P + Z)) - (L / (Q * (x - I) ** P + Z))\n","  x0=start\n","  arr2=np.array([funcatin(x) for x in np.arange(0,max_distance,0.001)])#dynamic function\n","\n","\n","  while x0<max_distance:# if the new point is bigger then max, just return \n","    plt.plot(np.linspace(0,max_distance,len(arr2)),arr2)\n","\n","    y0=funcatin(x0)\n","    m=derivative(x0)\n","\n","    lineA=lambda x:y0+m*(x-x0)+k\n","    lineB=lambda x:y0+m*(x-x0)-k\n","    #the 2 paralel lines \n","\n","    plt.plot(x0, y0, marker=\"o\", markersize=5, markeredgecolor=\"blue\", markerfacecolor=\"blue\")\n","    A_X_cut=cut(lineA,funcatin,x0)\n","    B_X_cut=cut(lineB,funcatin,x0)\n","\n","\n","    plt.show()\n","    if A_X_cut<0:# avoid negative\n","      A_X_cut=max_distance\n","    if B_X_cut<0:\n","      A_X_cut=max_distance   \n","\n","    x0=min(A_X_cut,B_X_cut)#minimum distance cut\n","\n","\n","  x = np.linspace(0,max_distance,500)\n","  plt.plot(x,x + (L / (Q * (x + I) ** P + Z)) - (L / (Q * (x - I) ** P + Z)))#show main dynamic\n","\n","\n","  for i in range(len(x_points)):\n","    plt.plot(x_points[i], y_points[i], marker=\"o\", markersize=5, markeredgecolor=\"red\", markerfacecolor=\"green\")#plot cut's on graph\n","  plt.show()\n","\n","\n","  lambdas=[]\n","  lambdas.append(drawLine(0,x_points[0],0,y_points[0]))\n","\n","\n","  for i in range(len(x_points)-1):\n","    lambdas.append(drawLine(x_points[i],x_points[i+1],y_points[i],y_points[i+1]))\n","\n","  lambdas.append(drawLine(x_points[len(x_points)-1],3,y_points[len(x_points)-1],3))\n","  plt.show()\n","  return lambdas,x_points,y_points"]},{"cell_type":"markdown","metadata":{"id":"e-Iig-FdXZ8s"},"source":["#Main"]},{"cell_type":"code","execution_count":7,"metadata":{"id":"6lt8Ux3pdY0b","executionInfo":{"status":"ok","timestamp":1654722151439,"user_tz":-180,"elapsed":12,"user":{"displayName":"Evja","userId":"12685707936098631523"}}},"outputs":[],"source":["\"\"\"\n","Original file is located at\n","    https://colab.research.google.com/drive/13R8T8i5OYbyyvjesEFC0cIwXebdGO4bp\n","\"\"\"\n","\n","\"\"\"We'll download the images in PNG format from [this page](https://course.fast.ai/datasets), using some helper functions from the `torchvision` and `tarfile` packages.\"\"\"\n","\n","#function  :  x + (L / (Q * (x + I) ** P + Z)) - (L / (Q * (x - I) ** P + Z)):https://www.desmos.com/calculator/0hiyjyun2f (move points to play with the parameters)\n","\n","\n","\n","\n","\n","setAll=False# will train and predict useing all the data ignoring the 2 above\n","#if false set the data manulaiy \n","#-----------------------------------------#\n","val_percent=0.5#x*5000 = dataset\n","train_percent=0.1#x*50000 = dataset\n","#old method:\n","# train_running_size=1000#train size of data {max is 50000}\n","# val_running_Size=1000#val size of data {max is 5000}\n","#-----------------------------------------#\n","\n","\n","\n","\n","#Relu parameters to compare\n","#-----------------------------------------#\n","addMaxRelu=False\n","addMean=False\n","HowManyTimesReRunRelu=1\n","#-----------------------------------------#\n","\n","\n","\n","\n","\n","checkCertainParams=True##if the one above is true set the parameters u want to check else it will igonre the value:\n","#-----------------------------------------------------------------------------------------#\n","L=55.9344471040698#0.1->2\n","Q=12 #0.01->0.2\n","P=2 #NO CHANGE\n","Z=10# NO CHANGE\n","I=0.0292401773821286 #1->3\n","howManyTimeToCheckTheCertainParams=1# how many times to run the cetrtain params \n","addMaxToCertain=False#will return the max score of the certain params\n","addMinToCertain=False#will return the min score of the certain params\n","addMeanToCertain=False#will return the mean of all the score's of the certain params\n","#-----------------------------------------------------------------------------------------#\n","\n","\n","\n","\n","#if checkCertainParams is false :config the range:\n","#-----------------------------------------------------------------------------------------#\n","LogarithmINC=True#insted of incresing when checking parameters with a constant , will will get to the to value useing geometric progression\n","\n","SIZEI=4#how many i to check\n","SIZEL=6#how many l to check\n","SIZEQ=7#how many q to check\n","#what number the paramter start and end\n","fromI=1\n","toI=10\n","\n","fromL=1\n","toL=50\n","\n","fromQ=0.01\n","toQ=10\n","#size of splits will, example fromI=1 toI=3,SIZEI=3 then i will check 1,2,3\n","#-----------------------------------------------------------------------------------------#\n","\n","\n","\n","#inequality parameters \n","#------------------------------------------------#\n","k=0.1#distance paralel\n","max_distance=3# maximum distance to find cut's,will return what found when pass the line \n","start=0#first paralel line will start from \n","runInequality=False# will run Inequality finder\n","setInequality=False# will set insted of dynamic Inequality function's ,above must be True\n","#------------------------------------------------#\n","\n","\n","#------------------nn parameters----------------#\n","batch_size = 128 #hyper parameter\n","epochs = 128\n","random_seed = 1\n","opt_func = torch.optim.Adam\n","\n","lr = 0.001#start learning rate\n","max_lr = 0.01# maximun learning rate\n","grad_clip = 0.1\n","weight_decay = 1e-4\n","opt_func = torch.optim.Adam#optimizer\n","#----------------------------------------------#\n","\n"]},{"cell_type":"code","execution_count":8,"metadata":{"id":"g3OlcxQVK605","executionInfo":{"status":"ok","timestamp":1654722151439,"user_tz":-180,"elapsed":11,"user":{"displayName":"Evja","userId":"12685707936098631523"}}},"outputs":[],"source":["#to not change:\n","#-------------#\n","\n","# setting the information needed for the nn for Inequality activation\n","# if runInequality:\n","\n","#   lambdas,x_points,y_points=findInequality(L,P,Q,I,Z)\n","\n","#   m=np.array([0.0]*len(lambdas))\n","  \n","#   x0=0.0\n","#   y0=0.0\n","#   b=[]\n","#   for i in range(len(x_points)):\n","#     m[i]=(y_points[i]-y0)/(x_points[i]-x0)\n","#     b.append(-m[i]*x0+y0)\n","#     x0=x_points[i]\n","#     y0=y_points[i]\n","\n","#   y1=10.0\n","#   x1=10.0\n","#   m[len(lambdas)-1]=(y1-y0)/(x1-x0)\n","#   b.append(-m[len(lambdas)-1]*x0+y0)\n","\n","#   \"\"\"Pick GPU if available, else CPU\"\"\"\n","#   if torch.cuda.is_available():\n","#       processor = torch.device('cuda') \n","#   else:\n","#       processor = torch.device('cpu') \n","\n","#   x_points=np.float32(np.array(x_points))\n","#   x_points=torch.tensor(x_points).to(device=processor)\n","\n","#   m=np.float32(m)\n","#   m=torch.tensor(m).to(device=processor)\n","\n","#   b=np.float32(np.array(b))\n","#   b=torch.tensor(b).to(device=processor)\n","\n","#   y_points=np.float32(np.array(y_points))\n","#   y_points=torch.tensor(y_points).to(device=processor)\n","\n","# val_size = 5000\n","\n","# #-------------#\n"]},{"cell_type":"markdown","metadata":{"id":"xvdg3F9aCIo5"},"source":["#Activation Function"]},{"cell_type":"code","execution_count":9,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"RzaA6sAZdgxB","executionInfo":{"status":"ok","timestamp":1654722151440,"user_tz":-180,"elapsed":11,"user":{"displayName":"Evja","userId":"12685707936098631523"}},"outputId":"8604e2d5-cae9-4ee9-bf01-9f49e198d698"},"outputs":[{"output_type":"stream","name":"stdout","text":["activation_function set\n"]}],"source":["if(checkCertainParams):\n","    L0=L\n","    Q0=Q\n","    I0=I\n","    Z0=Z\n","    P0=P\n","\n","def inequality_function(input):\n","    x=input\n","    x[x<0]=0\n","    c=x.clone()\n","    x[(0<c            )&  (c<=x_points[0])]=x[(0<c            )&(c<=x_points[0  ])]*m[0  ]+b[0  ]\n","    for i in range(len(x_points)-1):\n","      x[(x_points[i]<c)&(c<=x_points[i+1])]=x[(x_points[i]<c  )&(c<=x_points[i+1])]*m[i+1]+b[i+1]\n","    x[(x_points[len(x_points)-1]<c)       ]=x[(x_points[len(x_points)-1]<c)       ]*m[len(x_points)]+b[len(x_points)]\n","    return x\n","\n","class Inequality_function(nn.Module):\n","    def __init__(self):\n","        super().__init__() # init the base class\n","    def forward(self, input):\n","        return inequality_function(input) \n","\n","def dynamic(input):\n","    x=input\n","    x[x<0]=0\n","    if (checkCertainParams):\n","        x = x + (L0 / (Q0 * (x + I0) ** P0 + Z0)) - (L0 / (Q0 * (x - I0) ** P0 + Z0))\n","    else:\n","        x = x + (L / (Q * (x + I) ** P + Z)) - (L / (Q * (x - I) ** P + Z))\n","    return x\n","\n","class Dynamic(nn.Module):\n","    def __init__(self):\n","        super().__init__() # init the base class\n","    def forward(self, input):\n","        return dynamic(input) \n","\n","def relu(input):\n","    x=input\n","    x[x<0]=0\n","    return x\n","\n","class RELU(nn.Module):\n","    def __init__(self):\n","        super().__init__() # init the base class\n","    def forward(self, input):\n","        return relu(input) # simply apply already implemented SiLU\n","\n","def setParams(L_,Q_,P_,Z_,I_):\n","    global L\n","    global Q\n","    global P\n","    global Z\n","    global I\n","    L = L_\n","    Q = Q_\n","    P = P_\n","    Z = Z_\n","    I = I_\n","\n","    pass\n","\n","activation_function = RELU()\n","print(\"activation_function set\")\n","\n"]},{"cell_type":"markdown","metadata":{"id":"umKX-1TSiOqj"},"source":["# Load Data"]},{"cell_type":"code","source":["import torch\n","import numpy as np\n","from torch.utils.data import TensorDataset, DataLoader\n","\n","def load_data(path,show_all=False):\n","  folders = os.listdir(path)\n","  my_x=[]\n","  my_y=[]\n","  for Class in folders:\n","    files=os.listdir(path+\"/\"+Class)\n","    for File in files:\n","      # print(path+\"/\"+Class+\"/\"+File, \"is class is:\"+ Class)\n","      CSVData = open(path+\"/\"+Class+\"/\"+File)\n","      Array2d_result = np.loadtxt(CSVData, delimiter=\",\",skiprows=0)\n","      if show_all:\n","        print(\"Class:\",Class)\n","\n","      my_x.append(np.array(Array2d_result))\n","      my_y.append((float(Class)))\n","  tensor_x = torch.Tensor(my_x) # transform to torch tensor\n","  tensor_y = torch.Tensor(np.array(my_y)).type(torch.LongTensor)\n","\n","\n","  return TensorDataset(tensor_x,tensor_y)\n"],"metadata":{"id":"v_iBoJcyEilI","executionInfo":{"status":"ok","timestamp":1654722151998,"user_tz":-180,"elapsed":567,"user":{"displayName":"Evja","userId":"12685707936098631523"}}},"execution_count":10,"outputs":[]},{"cell_type":"code","execution_count":12,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"e7-Xj6KudwpQ","executionInfo":{"status":"ok","timestamp":1654722583287,"user_tz":-180,"elapsed":20366,"user":{"displayName":"Evja","userId":"12685707936098631523"}},"outputId":"99f42e11-477c-4f66-c8de-db9a5191f82d"},"outputs":[{"output_type":"stream","name":"stdout","text":["['generator.py', '__pycache__', 'datacounter.ipynb', 'resnet9.ipynb', 'log_May-10-2022_20-03-02.txt', 'log_May-10-2022_23-28-13.txt', 'writer.py', 'log_May-10-2022_23-38-57.txt', 'log_May-10-2022_23-42-27.txt', 'log_May-10-2022_23-43-12.txt', 'log_May-10-2022_23-44-36.txt', 'log_May-18-2022_22-22-49.txt', 'bestParams.txt', 'rnn.ipynb', 'writer.ipynb', 'data']\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:20: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:210.)\n"]}],"source":["\"\"\"### Loading and Processing Dataset\"\"\"\n","\n","\n","# Download the dataset\n","# dataset_url = 'https://s3.amazonaws.com/fast-ai-imageclas/cifar100.tgz'\n","# download_url(dataset_url, '.')\n","\n","# #Extract from archive\n","# with tarfile.open('./cifar100.tgz', 'r:gz') as tar:\n","#   tar.extractall(path='./data')\n","\n","# Look into the data directory\n","data_dir = './data'\n","print(os.listdir())\n","folders = os.listdir(data_dir + \"/train\")\n","classes=[]\n","# for folder in folders:\n","#   classes+=os.listdir(data_dir + \"/train/\"+folder)\n","classes=os.listdir(data_dir + \"/train\")\n","\n","\n","\n","#Data transforms (normalization and data augmentation)\n","\n","stats = ((0.4914, 0.4822, 0.4465),\n","         (0.2023, 0.1994, 0.2010))\n","\n","train_tfms = tt.Compose([tt.RandomCrop(32, padding=4, padding_mode='reflect'),\n","                         tt.RandomHorizontalFlip(),\n","                         tt.ToTensor(),\n","                         tt.Normalize(*stats, inplace=True)])\n","\n","valid_tfms = tt.Compose([tt.ToTensor(), tt.Normalize(*stats)])\n","\n","# PyTorch datasets\n","train_ds=[]\n","valid_ds=[]\n","# for folder in folders:\n","#   train_ds+=ImageFolder(data_dir+'/train/'+folder, train_tfms)\n","#   valid_ds+=ImageFolder(data_dir+'/test/'+folder, valid_tfms)\n","\n","\n","# train_ds = ImageFolder(data_dir+'/train', train_tfms)\n","# valid_ds = ImageFolder(data_dir+'/test', valid_tfms)\n","train_ds = load_data(data_dir+'/train')\n","valid_ds = load_data(data_dir+'/test')\n","\n","train_loader = torch.utils.data.DataLoader(dataset=train_ds,\n","                                           batch_size=batch_size, \n","                                           shuffle=True)\n","\n","test_loader = torch.utils.data.DataLoader(dataset=valid_ds,\n","                                          batch_size=batch_size, \n","                                          shuffle=False)\n","\n","\n","\n","# if not setAll :\n","#     data_S = list(range(0, len(train_ds),int(1/train_percent)))\n","#     test_S = list(range(0, len(valid_ds), int(1/val_percent)))\n","\n","#     train_ds = torch.utils.data.Subset(train_ds, data_S)\n","#     valid_ds = torch.utils.data.Subset(valid_ds, test_S)\n","    \n","\n","# Pytorch Data Loaders\n","train_dl = DataLoader(train_ds, batch_size, shuffle=True, num_workers=2, pin_memory=True)\n","valid_dl = DataLoader(valid_ds, batch_size*2, num_workers=2, pin_memory=True)\n","\n","\"\"\"### Uploading on GPU\"\"\"\n","\n","### Using a GPU\n","def get_default_device():\n","    \"\"\"Pick GPU if available, else CPU\"\"\"\n","    if torch.cuda.is_available():\n","        return torch.device('cuda')\n","        print(\"set on gpu\")\n","    else:\n","        return torch.device('cpu')\n","        print(\"set on cpu\")\n","\n","def to_device(data, device):\n","    \"\"\"Move tensor(s) to chosen device\"\"\"\n","    if isinstance(data, (list,tuple)):\n","        return [to_device(x, device) for x in data]\n","    return data.to(device, non_blocking=True)\n","\n","class DeviceDataLoader():\n","    \"\"\"Wrap a dataloader to move data to a device\"\"\"\n","    def __init__(self, dl, device):\n","        self.dl = dl\n","        self.device = device\n","\n","    def __iter__(self):\n","        \"\"\"Yield a batch of data after moving it to device\"\"\"\n","        for b in self.dl:\n","            yield to_device(b, self.device)\n","\n","    def __len__(self):\n","        \"\"\"Number of batches\"\"\"\n","        return len(self.dl)\n","\n","device = get_default_device()\n","device\n","\n","train_dl = DeviceDataLoader(train_dl, device)\n","valid_dl = DeviceDataLoader(valid_dl, device)"]},{"cell_type":"markdown","metadata":{"id":"v2DhICEXqo2-"},"source":["# RESNET 9"]},{"cell_type":"markdown","source":["## Net"],"metadata":{"id":"H7_aPQyKLEhK"}},{"cell_type":"code","execution_count":13,"metadata":{"id":"l2imA4jcez78","executionInfo":{"status":"ok","timestamp":1654722600931,"user_tz":-180,"elapsed":282,"user":{"displayName":"Evja","userId":"12685707936098631523"}}},"outputs":[],"source":["\n","def accuracy(outputs, labels):\n","    _, preds = torch.max(outputs, dim=1)\n","    return torch.tensor(torch.sum(preds == labels).item() / len(preds))\n","\n","class ImageClassificationBase(nn.Module):\n","    def training_step(self, batch):\n","        images, labels = batch\n","        out = self(images)                  # Generate predictions\n","        loss = F.cross_entropy(out, labels) # Calculate loss\n","        return loss\n","\n","    def validation_step(self, batch):\n","        images, labels = batch\n","        out = self(images)                    # Generate predictions\n","        loss = F.cross_entropy(out, labels)   # Calculate loss\n","        acc = accuracy(out, labels)           # Calculate accuracy\n","        return {'val_loss': loss.detach(), 'val_acc': acc}\n","\n","    def validation_epoch_end(self, outputs):\n","        batch_losses = [x['val_loss'] for x in outputs]\n","        epoch_loss = torch.stack(batch_losses).mean()   # Combine losses\n","        batch_accs = [x['val_acc'] for x in outputs]\n","        epoch_acc = torch.stack(batch_accs).mean()      # Combine accuracies\n","        return {'val_loss': epoch_loss.item(), 'val_acc': epoch_acc.item()}\n","\n","    def epoch_end(self, epoch, result):\n","        print(\"Epoch [{}], last_lr: {:.5f}, train_loss: {:.4f}, val_loss: {:.4f}, val_acc: {:.4f}\".format(\n","            epoch, result['lrs'][-1], result['train_loss'], result['val_loss'], result['val_acc']))\n","\n","\"\"\"Building our architecture:\"\"\"\n","# activation_function=nn.ReLU()\n","def conv_block(in_channels, out_channels, pool=False):\n","    layers = [nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1),\n","              nn.BatchNorm2d(out_channels),\n","            #   activation_function]\n","              nn.ReLU()]\n","    if pool: layers.append(nn.MaxPool2d(2))\n","    return nn.Sequential(*layers)\n","\n","class ResNet9(ImageClassificationBase):\n","    def __init__(self, in_channels, num_classes):\n","        super().__init__()\n","\n","        self.conv1 = conv_block(in_channels,4*9)\n","        self.conv2 = conv_block(4*9, 2*81, pool=True)\n","        self.res1 = nn.Sequential(conv_block(2*81, 2*81), conv_block(2*81, 2*81))\n","\n","        self.conv3 = conv_block(2*81, 2*162, pool=True)\n","        self.conv4 = conv_block(2*162, 2*324, pool=True)\n","        self.res2 = nn.Sequential(conv_block(2*324, 2*324), conv_block(2*324, 2*324))\n","\n","        \n","        self.conv5 = conv_block(2*324, 2*648, pool=True)\n","        self.conv6 = conv_block(2*648, 2*1296, pool=True)\n","        self.res3 = nn.Sequential(conv_block(2*1296, 2*1296), conv_block(2*1296, 2*1296))\n","\n","        \n","        self.conv7 = conv_block(2*1296, 2592, pool=True)\n","        self.conv8 = conv_block(2592, 5184, pool=True)\n","        self.res4 = nn.Sequential(conv_block(5184, 5184), conv_block(5184, 5184))\n","\n","        self.classifier = nn.Sequential(nn.MaxPool2d(2),\n","                                        nn.Flatten(),\n","                                        nn.Dropout(0.5),\n","                                        nn.Linear(31104, num_classes))\n","                                        # nn.Linear(324, num_classes))\n","\n","    def forward(self, xb):\n","        out = self.conv1(xb)\n","        out = self.conv2(out)\n","        out = self.res1(out) + out\n","        out = self.conv3(out)\n","        out = self.conv4(out)\n","        out = self.res2(out) + out\n","        out = self.conv5(out)\n","        out = self.conv6(out)\n","        out = self.res3(out) + out\n","        out = self.classifier(out)\n","\n","        \n","        return out\n","\n","\n","\n","\"\"\"### Training the Model\n","The improvements in fit functions are:\n","1. Learning rate scheduling: Instead of using a fixed learning rate, we will use a learning rate scheduler, which will change the learning rate after every batch of training. We will use one cycle policy [1cycle policy](https://sgugger.github.io/the-1cycle-policy.html).\n","2. Weight Decay: A regularization technique which prevents the weights from becoming too large by adding an additional term to the loss function.\n","3. Gradient clipping: Apart from the layer weights and outputs, it also helpful to limit the values of gradients to a small range to prevent undesirable changes in parameters due to large gradient values\n","\n","\"\"\"\n","\n","@torch.no_grad()\n","def evaluate(model, val_loader):\n","    model.eval()\n","    outputs = [model.validation_step(batch) for batch in val_loader]\n","    return model.validation_epoch_end(outputs)\n","\n","def get_lr(optimizer):\n","    for param_group in optimizer.param_groups:\n","        return param_group['lr']\n","\n","def fit_one_cycle(epochs, max_lr, model, train_loader, val_loader,\n","                  weight_decay=0, grad_clip=None, opt_func=torch.optim.SGD):\n","    torch.cuda.empty_cache()\n","    history = []\n","\n","    # Set up cutom optimizer with weight decay\n","    optimizer = opt_func(model.parameters(), max_lr, weight_decay=weight_decay)\n","    # Set up one-cycle learning rate scheduler\n","    sched = torch.optim.lr_scheduler.OneCycleLR(optimizer, max_lr, epochs=epochs,\n","                                                steps_per_epoch=len(train_loader))\n","\n","    for epoch in range(epochs):\n","        # Training Phase\n","        model.train()\n","        train_losses = []\n","        lrs = []\n","        for batch in train_loader:\n","            loss = model.training_step(batch)\n","            train_losses.append(loss)\n","            loss.backward()\n","\n","            # Gradient clipping\n","            if grad_clip:\n","                nn.utils.clip_grad_value_(model.parameters(), grad_clip)\n","\n","            optimizer.step()\n","            optimizer.zero_grad()\n","\n","            # Record & update learning rate\n","            lrs.append(get_lr(optimizer))\n","            sched.step()\n","\n","        # Validation phase\n","        result = evaluate(model, val_loader)\n","        result['train_loss'] = torch.stack(train_losses).mean().item()\n","        result['lrs'] = lrs\n","        model.epoch_end(epoch, result)\n","        history.append(result)\n","    return history"]},{"cell_type":"code","execution_count":38,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":235},"id":"4SQcsxI4UGnB","executionInfo":{"status":"error","timestamp":1654725075928,"user_tz":-180,"elapsed":274,"user":{"displayName":"Evja","userId":"12685707936098631523"}},"outputId":"5f66d40f-7a72-41c9-8608-85e0d329a380"},"outputs":[{"output_type":"error","ename":"TypeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-38-50ce6b905935>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m   \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_device\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mMy_nn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m   \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_dl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m   \u001b[0;32mif\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m<\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'val_acc'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"max changed: from {max} to {history[0]['val_acc']}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mTypeError\u001b[0m: __init__() takes 1 positional argument but 3 were given"]}],"source":["# max=0\n","# best_model=[]\n","# best_history=[]\n","# while True:\n","#   model = to_device(ResNet9(3,10), device)\n","#   history = [evaluate(model, valid_dl)]\n","#   if(max<history[0]['val_acc']):\n","#     print(f\"max changed: from {max} to {history[0]['val_acc']}\")\n","#     max=history[0]['val_acc']\n","#     best_history=history\n","#     best_model=model\n","  \n","#   if history[0]['val_acc'] >= 0.6:\n","#     break\n","#   else:\n","#     del model\n","#     del history\n","# history = [evaluate(model, valid_dl)]\n","# print(best_history)\n","# max"]},{"cell_type":"markdown","source":["## EliNet"],"metadata":{"id":"0JnPL3bILMeG"}},{"cell_type":"code","source":["def get_lr(optimizer):\n","    for param_group in optimizer.param_groups:\n","        return param_group['lr']\n","criterion=nn.CrossEntropyLoss()\n","def train(test_loader,train_loader,num_epochs,sequence_length,input_size,model,optimizer,max_lr=0.01,grad_clip=0.1):\n","  # Train the model\n","  sched = torch.optim.lr_scheduler.OneCycleLR(optimizer, max_lr, epochs=num_epochs,\n","                                                steps_per_epoch=len(train_loader))\n","  total_step = len(train_loader)\n","  lrs = []\n","\n","  for epoch in range(num_epochs):\n","      for i, (images, labels) in enumerate(train_loader):\n","\n","\n","          images = images.reshape(-1,sequence_length, input_size).to(device)\n","\n","\n","          labels = labels.to(device)\n","          \n","          # Forward pass\n","          outputs = model(images)\n","          # loss = criterion(outputs, torch.max(labels, 1)[1])\n","          # Backward and optimize\n","          # loss = F.mse_loss(outputs, labels)\n","          loss = criterion(outputs, labels)\n","\n","          loss.backward()\n","          if grad_clip:\n","                nn.utils.clip_grad_value_(model.parameters(), grad_clip)\n","          optimizer.step()\n","          optimizer.zero_grad()\n","          current_lr=get_lr(optimizer)\n","          lrs.append(current_lr)\n","          sched.step()\n","          if epoch % 100==0:\n","            testing(model,test_loader)\n","            pass\n","          if epoch % 10 == 0:\n","            print ('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}, lr: {:.6f}' \n","                    .format(epoch+1, num_epochs, i+1, total_step, loss.item(),current_lr))\n","\n","# Test the model\n","def testing(model,test_loader):\n","  # model.eval()\n","  with torch.no_grad():\n","      correct = 0\n","      total = 0\n","      for images, labels in test_loader:\n","          images = images.reshape(-1,1, 1000).to(device)\n","\n","          labels = labels.to(device)\n","          outputs = model(images)\n","\n","          _, predicted = torch.max(outputs.data, 1)\n","\n","          total += labels.size(0)\n","\n","          correct += (predicted == labels).sum().item()\n","\n","      # print('Test Accuracy of the model on the 10000 test images: {} %'.format(100 * correct / total)) \n","      print('Test Accuracy of the model on '+str(total)+' samples is: {}%'.format(100 * correct / total)+', '+str(correct)+' was correct') \n","\n","  return 100 * correct / total\n","\n","# Recurrent neural network (many-to-one)\n","class xRNN(nn.Module):\n","    def _init_(self, input_size, hidden_size, num_layers, num_classes):\n","        super(xRNN, self)._init_()\n","        self.hidden_size = hidden_size\n","        self.num_layers = num_layers\n","        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)\n","        self.fc = nn.Linear(hidden_size, num_classes)\n","    \n","    def forward(self, x):\n","        # Set initial hidden and cell states \n","        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(device) \n","        c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(device)\n","        \n","        # Forward propagate LSTM\n","        out, _ = self.lstm(x, (h0, c0))  # out: tensor of shape (batch_size, seq_length, hidden_size)\n","        \n","        # Decode the hidden state of the last time step\n","        out = self.fc(out[:, -1, :])\n","        return out\n","\n","#create the model\n","  # RAW_IRNN=create_raw_model_IRNN(input_size, hidden_size, num_layers)\n","  # model_CNN = My_nn(input_size, hidden_size, num_layers, num_classes).to(device)\n","  # model_RNN = RNN(input_size, hidden_size, num_layers,num_classes).to(device)\n","  # model_IRNN = Net(input_size, hidden_size, num_layers,RAW_IRNN,True).to(device)\n","  # # Loss and optimizer\n","  # criterion = nn.CrossEntropyLoss()\n","  # optimizer_CNN = torch.optim.Adam(model_CNN.parameters(), lr=learning_rate)\n","  # optimizer_RNN = torch.optim.Adam(model_RNN.parameters(), lr=learning_rate)\n","  # optimizer_IRNN = torch.optim.Adam(model_IRNN.parameters(), lr=learning_rate)\n","\n","  # # new_train(model,optimizer)\n","\n","  # # Train the model\n","\n","  # train(test_loader,train_loader,num_epochs,sequence_length,input_size,model_RNN,optimizer_RNN,max_lr,grad_clip)\n","  # # score_A,score_B,score_C=train_test_multi(test_loader,train_loader,num_epochs,sequence_length,input_size,\n","  # #                    model_CNN,optimizer_CNN,\"CNN\",\n","  # #                    max_lr=max_lr,grad_clip=grad_clip,\n","  # #                    model_B=model_RNN,optimizer_B=optimizer_RNN,model_name_B=\"RNN\",\n"],"metadata":{"id":"m0Le7EthLPF-","executionInfo":{"status":"ok","timestamp":1654724690074,"user_tz":-180,"elapsed":274,"user":{"displayName":"Evja","userId":"12685707936098631523"}}},"execution_count":31,"outputs":[]},{"cell_type":"markdown","source":["## EliNet2"],"metadata":{"id":"tMvvMojMTCMm"}},{"cell_type":"code","source":["import torchvision.models as models\n","class My_nn(nn.Module):\n","  def _init_(self, input_size, hidden_size, num_layers, num_classes):\n","    super(My_nn, self)._init_()\n","    input=input_size\n","    self.conv1_bn=nn.BatchNorm1d(1)\n","\n","    self.conv1=torch.nn.Conv1d(1,4,1)\n","    self.conv2=torch.nn.Conv1d(4,16,3)\n","    self.conv3=torch.nn.Conv1d(16,64,3)\n","\n","    self.conv4=torch.nn.Conv1d(64,32,3)\n","    self.conv5=torch.nn.Conv1d(32,16,3)\n","    self.conv6=torch.nn.Conv1d(16,8,3)\n","    self.conv7=torch.nn.Conv1d(8,4,3)\n","    self.conv8=torch.nn.Conv1d(4,2,1)\n","    self.conv9=torch.nn.Conv1d(2,1,1)\n","    self.max=nn.MaxPool1d(3, stride=2)\n","    self.softmax = nn.LogSoftmax()\n","\n","    self.fc = nn.Linear(int((input-2*6)), num_classes)\n","\n","    pass\n","\n","  def forward(self, x):\n","    out=x\n","    out=self.conv1_bn(out)\n","    out=self.conv1(out)\n","    out=self.conv2(out)\n","    out=self.conv3(out)\n","\n","    out=self.conv4(out)\n","    out=self.conv5(out)\n","    out=self.conv6(out)\n","    out=self.conv7(out)\n","    out=self.conv8(out)\n","    out=self.conv9(out)\n","    # out=self.max(out)\n","\n","    out = self.fc(out[:, -1, :])\n","\n","    # out=self.softmax(out)\n","    return out\n","\n","    pass"],"metadata":{"id":"HnwD3ONETETp","executionInfo":{"status":"ok","timestamp":1654725218902,"user_tz":-180,"elapsed":280,"user":{"displayName":"Evja","userId":"12685707936098631523"}}},"execution_count":39,"outputs":[]},{"cell_type":"code","source":["# Hyper-parameters\n","sequence_length =1\n","input_size =200*2\n","\n","hidden_size = 200*2\n","\n","\n","\n","#indrnn\n","lr=0.00002\n","time_steps=100\n","nlayer=3\n","no_cuda=False\n","batch_norm=True\n","bidirectional=True\n","log_interval=100\n","model_name=\"IndRNN\"\n","batch_size=2048\n","\n","num_layers = nlayer\n","num_classes = 2\n","num_epochs =20000\n","learning_rate =lr\n","max_lr=0.001\n","grad_clip=0.1"],"metadata":{"id":"uozbyB6FTaR7","executionInfo":{"status":"ok","timestamp":1654725220052,"user_tz":-180,"elapsed":3,"user":{"displayName":"Evja","userId":"12685707936098631523"}}},"execution_count":40,"outputs":[]},{"cell_type":"code","execution_count":14,"metadata":{"id":"8Ebj2fqiCmpC","executionInfo":{"status":"ok","timestamp":1654722607123,"user_tz":-180,"elapsed":320,"user":{"displayName":"Evja","userId":"12685707936098631523"}}},"outputs":[],"source":["def setFunc():# set dynamic or Inequality\n","  if setInequality:\n","    print(\"Inequality_function set\")\n","    return Inequality_function()\n","   \n","  else:\n","    print(\"Dynamic set\")\n","    return Dynamic()\n"]},{"cell_type":"code","execution_count":42,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":235},"id":"GdetGSoewyE8","executionInfo":{"status":"error","timestamp":1654725346371,"user_tz":-180,"elapsed":390,"user":{"displayName":"Evja","userId":"12685707936098631523"}},"outputId":"b9eba40e-2520-456e-c747-0c2e68d8849e"},"outputs":[{"output_type":"error","ename":"TypeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-42-828d573dfd10>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m                                           \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m                                           shuffle=False)\n\u001b[0;32m---> 18\u001b[0;31m \u001b[0mmodel_RNN\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMy_nn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_layers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnum_classes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0moptimizer_RNN\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_RNN\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_loader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msequence_length\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0minput_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmodel_RNN\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0moptimizer_RNN\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmax_lr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mgrad_clip\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mTypeError\u001b[0m: __init__() takes 1 positional argument but 5 were given"]}],"source":["# Device configuration\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","\n","#Data transforms (normalization and data augmentation)\n","\n","train_dataset = load_data(data_dir+'/train')\n","test_dataset = load_data(data_dir+'/test')\n","\n","# Data loader\n","\n","train_loader = torch.utils.data.DataLoader(dataset=train_dataset,\n","                                           batch_size=batch_size, \n","                                           shuffle=True)\n","\n","test_loader = torch.utils.data.DataLoader(dataset=test_dataset,\n","                                          batch_size=batch_size, \n","                                          shuffle=False)\n","model_RNN = My_nn(input_size, hidden_size, num_layers,num_classes).to(device)\n","optimizer_RNN = torch.optim.Adam(model_RNN.parameters(), lr=learning_rate)\n","train(test_loader,train_loader,num_epochs,sequence_length,input_size,model_RNN,optimizer_RNN,max_lr,grad_clip)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_18v-RZnUGnC","executionInfo":{"status":"aborted","timestamp":1654722152434,"user_tz":-180,"elapsed":11,"user":{"displayName":"Evja","userId":"12685707936098631523"}}},"outputs":[],"source":["# "]}],"metadata":{"accelerator":"GPU","colab":{"background_execution":"on","collapsed_sections":["kUmOJP2BAxdJ","H7_aPQyKLEhK"],"machine_shape":"hm","name":"resnet9.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.7"}},"nbformat":4,"nbformat_minor":0}